# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tn3YCP_XIFrYr1zo2jcUe3W6WGTTv3v6
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import Subset
import os
from google.colab import drive
drive.mount('/content/drive')

# Define data transformations
data_transforms = {
    'new_train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'new_val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}

# Define the data directory
data_dir = '/content/drive/MyDrive/Pneumonia_Detection_Proj/Ai Project/Pneumonia_Detection/Pneumonia X Rays Dataset'

# Load the full datasets
train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'new_train'), transform=data_transforms['new_train'])
val_dataset = datasets.ImageFolder(os.path.join(data_dir, 'new_val'), transform=data_transforms['new_val'])

# Create data loaders
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)
val_loader = torch.utils.data.DataLoader(val_dataset , batch_size=4, shuffle=False, num_workers=4)

# Define dataloaders and dataset sizes
dataloaders = {'train': train_loader, 'val': val_loader}
dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}

# Define class names
class_names = train_dataset.classes
print("Class names:", class_names)

# Load the pre-trained ResNet-18 model
model = models.resnet18(pretrained=True)

# Freeze all layers except the final classification layer
for name, param in model.named_parameters():
    if "fc" in name:  # Unfreeze the final classification layer
        param.requires_grad = True
    else:
        param.requires_grad = False

# Define the loss function
criterion = nn.CrossEntropyLoss()

# Define the optimizer (Adam)
optimizer = optim.Adam(
    filter(lambda p: p.requires_grad, model.parameters()),  # Use only trainable parameters
    lr=0.0001,  # Set learning rate for Adam
    betas=(0.9, 0.999),  # Default betas for Adam
    eps=1e-08,  # Default epsilon for numerical stability
    weight_decay=0  # Regularization term (L2 penalty, optional)
)

# Move the model to the GPU if available
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Training loop
num_epochs = 10
for epoch in range(num_epochs):
    print(f'Epoch {epoch+1}/{num_epochs}')
    print('-' * 10)

    for phase in ['train', 'val']:
        if phase == 'train':
            model.train()  # Set model to training mode
        else:
            model.eval()  # Set model to evaluate mode

        running_loss = 0.0
        running_corrects = 0

        for inputs, labels in dataloaders[phase]:
            # Move inputs and labels to the selected device
            inputs = inputs.to(device)
            labels = labels.to(device)

            # Zero the parameter gradients
            optimizer.zero_grad()

            # Forward pass
            with torch.set_grad_enabled(phase == 'train'):
                outputs = model(inputs)
                _, preds = torch.max(outputs, 1)
                loss = criterion(outputs, labels)

                # Backward pass and optimize only in training phase
                if phase == 'train':
                    loss.backward()
                    optimizer.step()

            # Statistics
            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)

        epoch_loss = running_loss / dataset_sizes[phase]
        epoch_acc = running_corrects.double() / dataset_sizes[phase]

        print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

    print()

print("Training complete!")

"""##Classification Report And Accuracy"""

from sklearn.metrics import classification_report, accuracy_score
import numpy as np

def evaluate_model(dataloader, dataset_size, phase='Validation'):
    model.eval()  # Set the model to evaluation mode
    all_preds = []
    all_labels = []
    running_corrects = 0

    with torch.no_grad():  # Disable gradient computation
        for inputs, labels in dataloader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            all_preds.append(preds.cpu().numpy())
            all_labels.append(labels.cpu().numpy())

            running_corrects += torch.sum(preds == labels.data)

    # Concatenate all predictions and labels
    all_preds = np.concatenate(all_preds)
    all_labels = np.concatenate(all_labels)

    accuracy = running_corrects.double() / dataset_size
    print(f"{phase} Accuracy: {accuracy:.4f}")

    # Print classification report
    print(f"\n{phase} Classification Report:")
    print(classification_report(all_labels, all_preds, target_names=class_names))



# Evaluate on training set
print("\nEvaluating on Training Set...")
evaluate_model(dataloaders['train'], dataset_sizes['train'], phase='Training')

# Evaluate on validation set
print("\nEvaluating on Validation Set...")
evaluate_model(dataloaders['val'], dataset_sizes['val'], phase='Validation')

"""##Saving The Model"""

# Define the path in your Google Drive where the model will be saved
save_path = '/content/drive/MyDrive/Pneumonia_Detection_Proj/Ai Project/Trained_Model_ResNet18_1.pth'

# Save the model
torch.save(model.state_dict(), save_path)

"""##Testing The Model"""

from torchvision import models

# Define the path to the saved model in Google Drive
saved_model_path = '/content/drive/MyDrive/Pneumonia_Detection_Proj/Ai Project/Trained_Model_ResNet18_1.pth'

# Load the model with the original architecture
model = models.resnet18(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, 1000)  # Match the saved model's output size
model.load_state_dict(torch.load(saved_model_path, map_location=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')))

# Modify the final layer for 2 classes
num_classes = 2
new_fc = nn.Linear(model.fc.in_features, num_classes)
model.fc = new_fc

# Optional: Initialize the new `fc` layer (since weights for new output classes are random)
nn.init.xavier_uniform_(model.fc.weight)
nn.init.zeros_(model.fc.bias)

# Move the model to the appropriate device
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

# Set the model to evaluation mode (if you want to use it for inference)
model.eval()

from PIL import Image

# Load and preprocess the unseen image
image_path = '/content/drive/MyDrive/Pneumonia_Detection_Proj/Ai Project/Pneumonia_Detection/Pneumonia X Rays Dataset/test/normal/IM-0103-0001.jpeg'
image = Image.open(image_path).convert('RGB') # Convert the image to RGB
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
input_tensor = preprocess(image)
input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension

import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

# Assuming you have your trained model loaded as 'model' and input_batch ready

# Perform prediction
with torch.no_grad():  # Disable gradient calculation for inference
    output = model(input_batch.to(device))
    _, predicted_idx = torch.max(output, 1)

# Map the predicted index to class names
class_names = ['Normal', 'Pneumonia']  # Assuming you have two classes: Normal and Pneumonia
predicted_class_name = class_names[predicted_idx.item()]


# Display the image with the predicted class name
image = np.array(image)
plt.imshow(image)
plt.axis('off')
plt.text(10, 10, f'Predicted: {predicted_class_name}', fontsize=12, color='white', backgroundcolor='red')
plt.show()